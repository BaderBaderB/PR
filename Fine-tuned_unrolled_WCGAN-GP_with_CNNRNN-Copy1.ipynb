{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d61833",
   "metadata": {},
   "source": [
    "### Librairie pour le modèle WCGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb466b4-946d-46b2-ad31-ad32e1d9aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.initializers import HeNormal,GlorotUniform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from traitement_image import image_processing\n",
    "from utils import generator_withCNN_loss, wasserstein_loss, generator_loss, generate_batches_cond, generate_cond, Conv2DCircularPadding, load_parquet_files_cond_red, newTorchSign, transform_batch\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4851c7",
   "metadata": {},
   "source": [
    "### Librairie pour le modèle CNN-RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb58c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split, Dataset, ConcatDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "from torchmetrics.regression import WeightedMeanAbsolutePercentageError, MeanAbsoluteError\n",
    "from e2cnn import gspaces\n",
    "from e2cnn import nn as enn\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfa219a",
   "metadata": {},
   "source": [
    "# Recupération du modèle CNN-RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le modèle CNN-RNN\n",
    "#On va utiliser des convolutions équivariantes aux symmétries et aux rotations à l'aide du package e2cnn.\n",
    "\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        self.g_space = gspaces.FlipRot2dOnR2(N=4) #Définition de l'espace invariant aux symmétries horizontales, verticales\n",
    "                                                  #et aux rotations de 90°\n",
    "        \n",
    "        in_type = enn.FieldType(self.g_space, [self.g_space.trivial_repr])\n",
    "        self.input_type = in_type\n",
    "\n",
    "        #Pour chaque couche de convolution équivariante, 8 sous-couches de convolutions parallèles sont en fait créés\n",
    "        #(une pour chaque combinaison de symmétrie/rotation possible). \n",
    "        #Plus besoin de donner des les images en rotation ou en symmétrie des microstructures en entraînement.\n",
    "        \n",
    "        self.conv1 = self._get_equivariant_conv(1,16)\n",
    "        self.conv2 = self._get_equivariant_conv(16, 32)\n",
    "        self.conv3 = self._get_equivariant_conv(32, 48)\n",
    "        self.conv4 = self._get_equivariant_conv(48, 64)\n",
    "        self.conv5_1 = self._get_equivariant_conv(64, 82)\n",
    "        self.conv5_2 = self._get_equivariant_conv(64, 82)\n",
    "        self.conv6_1 = self._get_equivariant_conv(82, 112)\n",
    "\n",
    "        #A la fin des couches de convolution équivariantes, on applique un \"Group Pooling\" pour grouper l'ensemble des caractéristiques\n",
    "        #trouvées par chaque combinaison de rotation / symmétrie afin d'en extraire des caractéristiques intrinsèques à la microstructure,\n",
    "        #indépendamment de sa rotation/symmétrie.\n",
    "        \n",
    "        self.gpool_1 = enn.GroupPooling(enn.FieldType(self.g_space, [self.g_space.regular_repr]*112))\n",
    "        self.gpool_2 = enn.GroupPooling(enn.FieldType(self.g_space, [self.g_space.regular_repr]*82))\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_1 = nn.Linear(360, 30)\n",
    "        self.fc_2 = nn.Linear(360, 30)\n",
    "        self.GRU_1 = nn.GRU(4*4*112, 360, num_layers = 3, dropout = 0.2) #Pour le module d'élasticité\n",
    "        self.lstm_2 = nn.LSTM(8*8*82, 360, num_layers = 2, dropout = 0.3)  #Pour le module de perte\n",
    "        \n",
    "        \n",
    "    def _get_equivariant_conv(self, in_channels, out_channels, kernel_size=3):\n",
    "        # Définir in_type selon le nombre de canaux d'entrée\n",
    "        if in_channels == 1:\n",
    "            in_type = enn.FieldType(self.g_space, [self.g_space.trivial_repr] * in_channels)\n",
    "        else:\n",
    "            in_type = enn.FieldType(self.g_space, [self.g_space.regular_repr] * in_channels)\n",
    "        \n",
    "        # Définir out_type (toujours regular_repr pour la sortie)\n",
    "        out_type = enn.FieldType(self.g_space, [self.g_space.regular_repr] * out_channels)\n",
    "        \n",
    "        # Créer le bloc de convolution\n",
    "        block = enn.SequentialModule(\n",
    "            enn.R2Conv(in_type, out_type, kernel_size=kernel_size, padding=1, padding_mode=\"circular\"),\n",
    "            enn.InnerBatchNorm(out_type),\n",
    "            enn.ReLU(out_type, inplace=True),\n",
    "            enn.PointwiseMaxPoolAntialiased(out_type, kernel_size=2)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Partie commune CNN\n",
    "        \n",
    "        x = enn.GeometricTensor(x, self.input_type)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        #Décomposition en 2 sous-blocs CNN+RNN parallèles:\n",
    "        \n",
    "        #1er bloc:\n",
    "        x1 = self.conv5_1(x)\n",
    "        x1 = self.conv6_1(x1)\n",
    "        x1 = self.gpool_1(x1)\n",
    "        x1 = x1.tensor\n",
    "        x1 = self.flatten(x1)\n",
    "        x1, h_1 = self.GRU_1(x1)\n",
    "        x1 = (self.fc_1(x1))\n",
    "        \n",
    "        #2nd bloc (moins complexe que le premier):\n",
    "        x2 = self.conv5_2(x)\n",
    "        x2 = self.gpool_2(x2)\n",
    "        x2 = x2.tensor\n",
    "        x2 = self.flatten(x2)\n",
    "        x2, h_2 = self.lstm_2(x2)\n",
    "        x2 = (self.fc_2(x2))\n",
    "        return x1,x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"/Users/Bader/Desktop/Mines 2A/Projet 2A/Ines/projet-dep/projet-dunne-main/Codes/best_model_1.pt\" #Endroit où le modèle a été sauvegardé\n",
    "modelCNN = CNNLSTM()\n",
    "modelCNN.load_state_dict(torch.load(load_path,map_location=torch.device('cpu')))\n",
    "modelCNN.eval()\n",
    "\n",
    "# Définir la fonction de perte\n",
    "criterion = WeightedMeanAbsolutePercentageError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4073f6d6-fecc-41be-a785-d36067341a65",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5a2fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generatorGP = tf.keras.models.load_model('/Users/Bader/Desktop/Mines 2A/Projet 2A/Ines/projet-dep/Projet_InesHafassaMaiza/model/generateur_red_gp.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c76021-ba59-4e3e-94da-d31df337cc97",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13697259-79ed-4a9c-b097-8b0b263b7fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminatorGP = tf.keras.models.load_model('/Users/Bader/Desktop/Mines 2A/Projet 2A/Ines/projet-dep/Projet_InesHafassaMaiza/model/discriminateur_red_gp.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43612eb0-e0b2-4804-84d0-29bab9f0ac74",
   "metadata": {},
   "source": [
    "# WCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca1b64-c4a1-4de2-81cb-5c2743c7e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(models.Model):\n",
    "    def __init__(self, generator, discriminator, modelCNN ,latent_dim, batch_size):\n",
    "        \"\"\"\n",
    "        Définition du modèle complet générateur + discriminateur\n",
    "        :param generator: le générateur\n",
    "        :param discriminator: le disriminateur\n",
    "        :param data_path: Le chemin d'accès aux données prétraitées\n",
    "        \"\"\"\n",
    "        super(GAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.modelCNN = modelCNN\n",
    "        self.compile_discriminator()\n",
    "        self.compile_gan()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.cond_dim = 62\n",
    "        self.image_dim = (128,128)\n",
    "        self.batch_size = batch_size\n",
    "        # Définir les optimizers ICI, pas dans les sous-modèles\n",
    "        self.generator_optimizer = RMSprop(learning_rate=0.005)\n",
    "        self.discriminator_optimizer = RMSprop(learning_rate=0.00005)\n",
    "        \n",
    "        # Compiler le discriminateur\n",
    "        self.discriminator.compile(\n",
    "            optimizer=self.discriminator_optimizer,\n",
    "            loss=self.gradient_penalty_loss\n",
    "        )\n",
    "\n",
    "    def gradient_penalty_loss(self, real_images, fake_images, real_sign):\n",
    "        \"\"\"\n",
    "        Calcul du gradient penalty pour un WGAN-GP.\n",
    "        :param real_images: Données réelles.\n",
    "        :param fake_images: Données générées.\n",
    "        :param real_sign: Signature réelle.\n",
    "        :return: Perte de gradient penalty.\n",
    "        \"\"\"\n",
    "        lambda_gp = 10\n",
    "        \n",
    "        # Interpolation entre les échantillons réels et générés\n",
    "        alpha = tf.random.uniform((self.batch_size, 1, 1, 1), minval=0.0, maxval=1.0)\n",
    "        interpolated = (alpha * real_images) + ((1 - alpha) * fake_images)\n",
    "        #interpolated = np.array(interpolated)\n",
    "        real_sign = tf.convert_to_tensor(real_sign)\n",
    "        \n",
    "        # Calcul des prédictions du discriminateur sur les échantillons interpolés\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(interpolated)  # Surveiller interpolated pour le calcul des gradients\n",
    "            pred = self.discriminator([interpolated, real_sign])\n",
    "                                                     #, training=True\n",
    "                                                     \n",
    "        \n",
    "        # Calcul des gradients\n",
    "        gradients = tape.gradient(pred, interpolated)\n",
    "        \n",
    "        # Calcul de la norme des gradients\n",
    "        gradients_sqr = tf.square(gradients)\n",
    "        gradients_sqr_sum = tf.reduce_sum(gradients_sqr, axis=[1, 2, 3])\n",
    "        gradient_l2_norm = tf.sqrt(gradients_sqr_sum)\n",
    "        \n",
    "        # Calcul du gradient penalty\n",
    "        gradient_penalty = tf.reduce_mean(tf.square(gradient_l2_norm - 1.0))\n",
    "        \n",
    "        # Perte totale\n",
    "        return lambda_gp * gradient_penalty\n",
    "            \n",
    "        \n",
    "    def compile_discriminator(self):\n",
    "        self.discriminator.compile(loss=self.gradient_penalty_loss, optimizer=RMSprop(learning_rate=0.00005), metrics=['accuracy'])\n",
    "        #self.discriminator.trainable = False\n",
    "\n",
    "    # def compile_gan(self):\n",
    "    #     latent = layers.Input(shape=(self.generator.latent_dim,))\n",
    "    #     cond = layers.Input(shape=(self.generator.cond_dim,))\n",
    "    #     fake_image = self.generator([latent, cond])\n",
    "    #     input_disc = [fake_image, cond]\n",
    "    #     validity = self.discriminator(input_disc)\n",
    "\n",
    "    #     self.model = models.Model([latent,cond], validity)\n",
    "    #     self.model.compile(loss=generator_loss, optimizer=RMSprop(learning_rate=0.005))\n",
    "\n",
    "    def compile_gan(self):\n",
    "        # Initialiser les optimizers\n",
    "        self.generator_optimizer = RMSprop(learning_rate=0.005)\n",
    "        self.discriminator_optimizer = RMSprop(learning_rate=0.00005)\n",
    "        \n",
    "        # Compiler le discriminateur (Wasserstein + GP)\n",
    "        self.discriminator.compile(\n",
    "            optimizer=self.discriminator_optimizer,\n",
    "            loss=self.gradient_penalty_loss\n",
    "        )\n",
    "        \n",
    "        # Le générateur nécessite un entraînement personnalisé (via un pas manuel)\n",
    "        self.discriminator.trainable = False  # Gelé pendant l'entraînement du générateur\n",
    "\n",
    "    def generate_latent_points(self, latent_dim, n_samples):\n",
    "        \"\"\"\n",
    "        Génère n_samples vecteurs latents\n",
    "        :param latent_dim: dimension de l'espace latent\n",
    "        :param n_samples: taille de l'échantillon crée\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x_input = np.random.randn(latent_dim * n_samples)\n",
    "        x_input = x_input.reshape(n_samples, latent_dim)\n",
    "        return x_input\n",
    "\n",
    "    def generate_cond(self, cond):\n",
    "        \"\"\"\n",
    "        Mise en forme de la condition avant passage dans le modèle\n",
    "        :param cond: Liste des conditions du batch correspondant lors de l'entraînement\n",
    "        :return: les conditions mises en forme\n",
    "        \"\"\"\n",
    "        x_input = pd.concat(cond, axis=1)\n",
    "        x_input = x_input.T\n",
    "        x_input = np.array(x_input)\n",
    "        return x_input\n",
    "    \n",
    "\n",
    "    def generate_real_samples(self, n_samples):\n",
    "        \"\"\"\n",
    "        \n",
    "        Charge un batch d'images réelles\n",
    "        :param n_samples: taille du batch\n",
    "        :return: Batch d'images réelles\n",
    "        \"\"\"\n",
    "        dfs = self.data\n",
    "        dfs_array = [(df[0].to_numpy(), df[0].to_numpy()) for df in dfs] ### /!\\\n",
    "        # np.random.shuffle(dfs_array)\n",
    "\n",
    "        sampled_indices = np.random.choice(len(dfs_array), size=n_samples, replace=False)\n",
    "\n",
    "        # Sélectionner les arrays échantillonnés\n",
    "        real_samples = [dfs_array[i] for i in sampled_indices]\n",
    "        real_samples = np.stack(real_samples, axis=0)\n",
    "        real_samples = np.expand_dims(real_samples, axis=-1)\n",
    "        labels = -(np.ones((n_samples, 1))) # Création des labels associés aux images réelles\n",
    "\n",
    "        return real_samples, labels\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c078b103-155a-4427-8c84-f47390aa5e86",
   "metadata": {},
   "source": [
    "### Fonctions (plot, save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ccb3a-1ca2-4e35-b593-226b71d0ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_training_history(d_losses, g_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(d_losses, label='Discriminator Loss', linestyle='--')\n",
    "    plt.plot(g_losses, label='Generator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('WGAN Training History')\n",
    "    plt.show()\n",
    "\n",
    "def generate_and_save_outputs(root_folder, gan, latent_dim):\n",
    "    \"\"\"\n",
    "    CHarge des signatures de root_folder puis génère les structures associées selon le gan\n",
    "    :param root_folder:\n",
    "    :param gan:\n",
    "    :param latent_dim:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Parcourir tous les sous-dossiers\n",
    "    for folder in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            condition_file = os.path.join(folder_path, 'craft_s12.parquet')\n",
    "\n",
    "            # Vérifier si le fichier de condition existe\n",
    "            if os.path.exists(condition_file):\n",
    "                # Charger le DataFrame de condition\n",
    "                condition = pd.read_parquet(condition_file)\n",
    "                condition = condition.T\n",
    "                # Générer un vecteur latent aléatoire\n",
    "                latent_vector = gan.generate_latent_points(latent_dim, 1)\n",
    "\n",
    "                # Générer une sortie du GAN\n",
    "                generated_output = gan.generator.predict([latent_vector, condition])\n",
    "\n",
    "                # Sauvegarder la sortie dans le même dossier\n",
    "                output_file = os.path.join(folder_path, 'generated_output_red.npy')\n",
    "                np.save(output_file, generated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b8ea46",
   "metadata": {},
   "source": [
    "## Training WCGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4e2a04-eca8-4fed-88e2-c1de03710766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unrolled_wgan_gp(generator, discriminator, gan, data, latent_dim, \n",
    "                           n_epochs, n_critic, batch_size, K_unroll=5):\n",
    "    \"\"\"\n",
    "    Entraînement d'un Unrolled WGAN-GP\n",
    "    :param generator: le générateur\n",
    "    :param discriminator: le discriminateur\n",
    "    :param gan: le modèle GAN complet\n",
    "    :param data: données d'entraînement\n",
    "    :param latent_dim: dimension de l'espace latent\n",
    "    :param n_epochs: nombre d'époques\n",
    "    :param n_critic: nombre de mises à jour du discriminateur par mise à jour du générateur\n",
    "    :param batch_size: taille des batchs\n",
    "    :param K_unroll: nombre de pas de déroulement du discriminateur\n",
    "    \"\"\"\n",
    "    d_losses, g_losses = [], []\n",
    "    current_epoch = 0\n",
    "\n",
    "    gan.discriminator.compile(loss=gan.gradient_penalty_loss, optimizer=RMSprop(learning_rate=0.00005), metrics=['accuracy'])\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        batches = generate_batches_cond(data, batch_size)\n",
    "        current_epoch += 1\n",
    "    \n",
    "\n",
    "\n",
    "        for batch in batches:\n",
    "            # Mettre à jour le discriminateur plusieurs fois\n",
    "            for _ in range(n_critic):\n",
    "                print(\"epoch\",epoch)\n",
    "                y_real = -np.ones((batch_size, 1))  # Labels réels (-1)\n",
    "                \n",
    "                voxel_data = [np.expand_dims(sample[0], axis=-1) for sample in batch]\n",
    "                signature_data = [sample[1].to_numpy() for sample in batch]\n",
    "\n",
    "                X_real_tab_np = np.array(voxel_data)\n",
    "                X_real_sign_np = np.array(signature_data)\n",
    "\n",
    "                latent = gan.generate_latent_points(latent_dim, batch_size)\n",
    "                real_sign = np.squeeze(X_real_sign_np, axis=-1)\n",
    "                input_model = layers.Concatenate()([latent, real_sign])\n",
    "                X_fake_tab_np = gan.generator.predict(input_model)\n",
    "\n",
    "                # Sauvegarde des poids du discriminateur\n",
    "                original_disc_weights = discriminator.get_weights()\n",
    "\n",
    "                discriminator.trainable = True  # Rendre le discriminateur entraînable\n",
    "\n",
    "\n",
    "                with tf.GradientTape() as disc_tape:\n",
    "                    pred_real = discriminator([X_real_tab_np, X_real_sign_np], training=True)\n",
    "                    pred_fake = discriminator([X_fake_tab_np, X_real_sign_np], training=True)\n",
    "                    wasserstein_loss = tf.reduce_mean(pred_fake) - tf.reduce_mean(pred_real)\n",
    "                    gp_loss = gan.gradient_penalty_loss(X_real_tab_np, X_fake_tab_np, X_real_sign_np)\n",
    "                    d_loss = wasserstein_loss + gp_loss\n",
    "\n",
    "                gradients = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "                print(f\"Discriminator Gradients: {[g.numpy().sum() for g in gradients if g is not None]}\")\n",
    "\n",
    "                gan.discriminator_optimizer.apply_gradients(zip(gradients, discriminator.trainable_variables))\n",
    "\n",
    "            # Unrolling du Discriminateur\n",
    "            for _ in range(K_unroll):\n",
    "                with tf.GradientTape() as unroll_tape:\n",
    "                    pred_real = discriminator([X_real_tab_np, X_real_sign_np], training=True)\n",
    "                    pred_fake = discriminator([X_fake_tab_np, X_real_sign_np], training=True)\n",
    "                    wasserstein_loss = tf.reduce_mean(pred_fake) - tf.reduce_mean(pred_real)\n",
    "                    gp_loss = gan.gradient_penalty_loss(X_real_tab_np, X_fake_tab_np, X_real_sign_np)\n",
    "                    d_loss_unroll = wasserstein_loss + gp_loss\n",
    "\n",
    "                gradients_unroll = unroll_tape.gradient(d_loss_unroll, discriminator.trainable_variables)\n",
    "                discriminator.set_weights([\n",
    "                    w - 0.00005 * g for w, g in zip(discriminator.get_weights(), gradients_unroll)\n",
    "                ])\n",
    "\n",
    "            # **Mise à jour du générateur**\n",
    "            latent = gan.generate_latent_points(latent_dim, batch_size)\n",
    "            cond = [sample[1] for sample in batch]\n",
    "            cond = gan.generate_cond(cond)\n",
    "            real_sign = np.expand_dims(cond, axis=-1)\n",
    "            real_sign = tf.convert_to_tensor(real_sign)\n",
    "\n",
    "            input_model = layers.Concatenate()([latent, cond])\n",
    "\n",
    "            with tf.GradientTape() as gen_tape:\n",
    "                fake_images = gan.generator(input_model, training=True)\n",
    "                validity = discriminator([fake_images, real_sign], training=False)\n",
    "                g_loss = generator_withCNN_loss(\n",
    "                    y_true=None, \n",
    "                    y_pred=validity, \n",
    "                    real_sign=real_sign, \n",
    "                    fake_images=fake_images,\n",
    "                    CNNmodel=modelCNN,  \n",
    "                    criterion=criterion,\n",
    "                    lambda_sign=-10000.0\n",
    "                )\n",
    "\n",
    "            gradients = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "            print(f\"Generator Gradients: {[g.numpy().sum() for g in gradients if g is not None]}\")\n",
    "            gan.generator_optimizer.apply_gradients(zip(gradients, generator.trainable_variables))\n",
    "\n",
    "            # Restauration des poids originaux du discriminateur\n",
    "            discriminator.set_weights(original_disc_weights)\n",
    "\n",
    "            # Enregistrer les pertes\n",
    "            d_losses.append(-d_loss)\n",
    "            g_losses.append(g_loss)\n",
    "            \n",
    "        # Sélectionner aléatoirement deux indices de conditions\n",
    "            random_indices = np.random.choice(cond.shape[0], 2, replace=False)\n",
    "            conditions_selected = cond[random_indices]\n",
    "        # Générer des points latents\n",
    "            latent_points = gan.generate_latent_points(latent_dim, 2)  # Pour deux échantillons\n",
    "\n",
    "            entree = layers.Concatenate()([latent_points, conditions_selected])\n",
    "        # Générer des images avec le générateur\n",
    "            \n",
    "            generated_images = gan.generator.predict(entree)\n",
    "            \n",
    "            print(f\"Generated Images Shape: {generated_images.shape}\")\n",
    "\n",
    "\n",
    "        # Afficher les images\n",
    "            for i in range(2):\n",
    "                plt.imshow(generated_images[i], cmap='gray')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "        # Display results \n",
    "        plot_training_history(d_losses, g_losses)\n",
    "        print(f\"Epoch {current_epoch}, [D loss: {d_losses[-1]}], [G loss: {g_loss}]\")\n",
    "        generator_weights = [layer.get_weights()[0].flatten() for layer in generator.layers if len(layer.get_weights()) > 0]\n",
    "        discriminator_weights = [layer.get_weights()[0].flatten() for layer in discriminator.layers if len(layer.get_weights()) > 0]\n",
    "        \n",
    "        plt.figure(figsize=(10,5))\n",
    "        for weights in generator_weights :\n",
    "            plt.hist(weights, bins = 50, alpha = 0.5)\n",
    "        plt.title('Histogramme des poids du générateur')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10,5))\n",
    "        for weights in discriminator_weights :\n",
    "            plt.hist(weights, bins = 50, alpha = 0.5)\n",
    "        plt.title('Histogramme des poids du discriminateur')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0d798e-4c9c-44c9-b1ec-4e6a4e7d8ede",
   "metadata": {},
   "source": [
    "**Lancement du code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c42926-1923-4ea2-9b7f-355a2d5e41b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#with open(\"/Users/Bader/Desktop/Mines 2A/Projet 2A/Ines/projet-dep/Projet_Daviet_Colin/preproc2.py\", \"r\") as file:\n",
    "    #exec(file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826bb4c-1a3d-47f3-ac61-61bc8f43d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le nombre d'époques et la taille du lot\n",
    "latent_dim = 50\n",
    "n_epochs = 2\n",
    "batch_size = 64\n",
    "n_critic = 1\n",
    "data_path = '/Users/Bader/Desktop/Mines 2A/Projet 2A/Ines/projet-dep/Projet_InesHafassaMaiza/DATA2'  # Définir le chemin d'accès aux données\n",
    "data = load_parquet_files_cond_red(data_path, test = False)\n",
    "print(f\"Taille de `data`: {len(data)}\")\n",
    "if len(data) == 0:\n",
    "    print(\"Aucune donnée n'a été chargée.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0783c0b7",
   "metadata": {},
   "source": [
    "# Génération d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd15cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "gan = GAN(generatorGP, discriminatorGP, modelCNN, latent_dim, batch_size)\n",
    "\n",
    "generatorGP.summary()\n",
    "discriminatorGP.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_weights = [layer.get_weights()[0].flatten() for layer in generatorGP.layers if len(layer.get_weights()) > 0]\n",
    "discriminator_weights = [layer.get_weights()[0].flatten() for layer in discriminatorGP.layers if len(layer.get_weights()) > 0]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for weights in generator_weights :\n",
    "    plt.hist(weights, bins = 50, alpha = 0.5)\n",
    "plt.title('Histogramme des poids du générateur')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for weights in discriminator_weights :\n",
    "    plt.hist(weights, bins = 50, alpha = 0.5)\n",
    "plt.title('Histogramme des poids du discriminateur')\n",
    "plt.show()\n",
    "\n",
    "# Entraîner le GAN\n",
    "train_unrolled_wgan_gp(generatorGP, discriminatorGP, gan, data, latent_dim, n_epochs, n_critic, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955c2d8-7bc5-4a5a-b7c7-0369aa74cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generatorGP.save('/Users/Bader/Desktop/Mines 2A/Projet 2A/Ines/projet-dep/Projet_InesHafassaMaiza/model/fine_tuned_unrolled_generateur_red_gp_with_CNN.keras')\n",
    "#discriminatorGP.save('/Users/Bader/Desktop/Mines 2A/Projet 2A/Ines/projet-dep/Projet_InesHafassaMaiza/model/fine_tuned_unrolled_discriminateur_red_gp_with_CNN.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7211fd53-2288-4bca-8a35-75cb6635dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "latent_dim = 38\n",
    "n_epochs = 2\n",
    "batch_size = 64\n",
    "n_critic = 1\n",
    "#generatorGP = tf.keras.models.load_model('C:/Users/Bader/Desktop/Mines 2A/Projet 2A/Ines/model2/generateur_red_gp2.keras')\n",
    "generatorGP = tf.keras.models.load_model('/Users/Bader/Desktop/Mines 2A/Projet 2A/Ines/projet-dep/Projet_InesHafassaMaiza/model/generateur_red_gp.keras')\n",
    "#discriminatorGP = tf.keras.models.load_model('/Users/Bader/Desktop/Mines 2A/Projet 2A/Ines/projet-dep/Projet_InesHafassaMaiza/model/fine_tuned_unrolled_discriminateur_red_gp_with_CNN.keras')\n",
    "#discriminatorGP = tf.keras.models.load_model('C:/Users/Bader/Desktop/Mines 2A/Projet 2A/Ines/model2/discriminateur_red_gp2.keras')\n",
    "discriminatorGP = tf.keras.models.load_model('/Users/Bader/Desktop/Mines 2A/Projet 2A/Ines/projet-dep/Projet_InesHafassaMaiza/model/discriminateur_red_gp.keras')\n",
    "gan = GAN(generatorGP, discriminatorGP, modelCNN, latent_dim, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0602a1-3818-4fc3-a051-b2ef2e8bad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from utils import transform_batch, newTorchSign\n",
    "from traitement_image import image_processing\n",
    "from scipy import stats  # Pour IC à 95%\n",
    "\n",
    "# === Paramètres ===\n",
    "n_samples = 10000\n",
    "latent_dim = 38\n",
    "batch_size = 12\n",
    "n_batches = n_samples // batch_size\n",
    "\n",
    "# === Accumulateurs pour les erreurs ===\n",
    "all_errors_modulus1 = []\n",
    "all_errors_modulus2 = []\n",
    "\n",
    "# === Boucle principale ===\n",
    "for batch_idx in range(n_batches):\n",
    "    print(f\"Batch {batch_idx+1}/{n_batches}\")\n",
    "    \n",
    "    # === Génération des données ===\n",
    "    batches = generate_batches_cond(data, batch_size)\n",
    "    i = random.randrange(len(batches))\n",
    "    batch = batches[i]\n",
    "    \n",
    "    cond = gan.generate_cond([sample[1] for sample in batch])\n",
    "    real_sign = np.expand_dims(cond, axis=-1)\n",
    "    z = gan.generate_latent_points(latent_dim, batch_size)\n",
    "\n",
    "    input_model = layers.Concatenate()([z, cond])\n",
    "    generated_samples = generatorGP.predict_on_batch(input_model)\n",
    "\n",
    "    # === Préparation et prédiction ===\n",
    "    fake_images_torch = transform_batch(generated_samples)\n",
    "    pred_sign1, pred_sign2 = modelCNN(fake_images_torch)\n",
    "    real_sign1, real_sign2 = newTorchSign(real_sign)\n",
    "\n",
    "    # === Calcul des erreurs ===\n",
    "    for i in range(batch_size):\n",
    "        err1 = criterion(real_sign1[i], pred_sign1[i]).item()\n",
    "        err2 = criterion(real_sign2[i], pred_sign2[i]).item()\n",
    "        all_errors_modulus1.append(err1)\n",
    "        all_errors_modulus2.append(err2)\n",
    "\n",
    "# === Calculs statistiques ===\n",
    "errors1 = np.array(all_errors_modulus1)\n",
    "errors2 = np.array(all_errors_modulus2)\n",
    "\n",
    "# Moyennes\n",
    "mean1 = np.mean(errors1)\n",
    "mean2 = np.mean(errors2)\n",
    "\n",
    "# Écart-types\n",
    "std1 = np.std(errors1, ddof=1)  # ddof=1 pour échantillon\n",
    "std2 = np.std(errors2, ddof=1)\n",
    "\n",
    "# Erreurs-types\n",
    "stderr1 = std1 / np.sqrt(len(errors1))\n",
    "stderr2 = std2 / np.sqrt(len(errors2))\n",
    "\n",
    "# Intervalles de confiance à 95%\n",
    "ci1 = stats.norm.interval(0.95, loc=mean1, scale=stderr1)\n",
    "ci2 = stats.norm.interval(0.95, loc=mean2, scale=stderr2)\n",
    "\n",
    "# === Affichage final ===\n",
    "print(\"\\n--- Résultats sur {:,} microstructures ---\".format(n_samples))\n",
    "print(f\"Storage modulus (MAPE) : {mean1*100:.2f} ± {stderr1*100:.2f} % (IC 95%: {ci1[0]*100:.2f} – {ci1[1]*100:.2f} %)\")\n",
    "print(f\"Loss modulus    (MAPE) : {mean2*100:.2f} ± {stderr2*100:.2f} % (IC 95%: {ci2[0]*100:.2f} – {ci2[1]*100:.2f} %)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745a52c-88fd-4810-a9ac-f17ea586f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter, distance_transform_edt\n",
    "from skimage.morphology import disk, binary_erosion\n",
    "from skimage.segmentation import watershed \n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label\n",
    "import cv2\n",
    "from e2cnn import gspaces\n",
    "from e2cnn.nn import GeometricTensor\n",
    "def image_processing_single(image_fake):\n",
    "    W, H = 128, 128  # Taille de l’image\n",
    "    dpi = 25\n",
    "    fixed_radius = H * 3.98942280401433e-2  # Rayon fixe\n",
    "\n",
    "    # Étape 1 : conversion en image PIL\n",
    "    X_fake_reshaped = (image_fake * 255).astype(np.uint8).reshape(H, W)\n",
    "    image = Image.fromarray(X_fake_reshaped, mode='L') \n",
    "\n",
    "    # Conversion OpenCV\n",
    "    image_cv = np.array(image)\n",
    "    smoothed = gaussian_filter(image_cv, sigma=0.5)\n",
    "    tresh_value = threshold_otsu(smoothed)\n",
    "    binary = (smoothed > tresh_value).astype(np.uint8) * 255\n",
    "    binary_opened = binary_erosion(binary, disk(2))\n",
    "\n",
    "    distance = distance_transform_edt(binary_opened)\n",
    "    markers = label(distance > 0.3 * distance.max())\n",
    "    local_maxi = watershed(-distance, markers, mask=binary_opened)\n",
    "    binary_local_maxi = (local_maxi > 0).astype(np.uint8) * 255\n",
    "\n",
    "    # Étape 2 : création de l'image avec cercles\n",
    "    gray = binary_local_maxi\n",
    "    _, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(W/dpi, H/dpi), dpi=dpi)\n",
    "    ax.imshow(np.zeros_like(image_cv), cmap='gray')\n",
    "\n",
    "    for cnt in contours:\n",
    "        M = cv2.moments(cnt)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "            ax.add_patch(plt.Circle((cx, cy), fixed_radius, color='white', fill=True, alpha=0.9))\n",
    "            for dx, dy in [(-W, 0), (W, 0), (0, -H), (0, H), (-W, -H), (-W, H), (W, -H), (W, H)]:\n",
    "                ax.add_patch(plt.Circle((cx + dx, cy + dy), fixed_radius, color='white', fill=True, alpha=0.9))\n",
    "\n",
    "    ax.set_position([0, 0, 1, 1])\n",
    "    ax.set_xticks([]), ax.set_yticks([]), ax.set_frame_on(False), ax.set_facecolor('black')\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    image_array = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "    plt.close(fig)\n",
    "\n",
    "    gray_image = np.mean(image_array[:H, :W, :3], axis=2)\n",
    "    binary_array = (gray_image > 100).astype(np.float32)\n",
    "\n",
    "    binary_array = np.expand_dims(binary_array, axis=0)\n",
    "    upscaled_array = np.repeat(np.repeat(binary_array, 2, axis=1), 2, axis=2)\n",
    "\n",
    "    tensor = torch.from_numpy(upscaled_array)\n",
    "    tensor = torch.where(tensor == 1, torch.tensor(0.5), torch.tensor(-0.5))\n",
    "    return tensor  # shape (1, 256, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb62e11-3690-4ddb-87ca-1ae9e1768bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from utils import transform_batch, newTorchSign\n",
    "from traitement_image import image_processing\n",
    "import random\n",
    "\n",
    "# === Paramètres ===\n",
    "n_samples = 10000\n",
    "latent_dim = 38\n",
    "batch_size = 12\n",
    "n_batches = n_samples // batch_size\n",
    "\n",
    "# === Accumulateurs pour les erreurs ===\n",
    "all_errors_modulus1 = []\n",
    "all_errors_modulus2 = []\n",
    "\n",
    "# === Boucle principale ===\n",
    "for batch_idx in range(n_batches):\n",
    "    print(f\"Batch {batch_idx+1}/{n_batches}\")\n",
    "    \n",
    "    # Génération d'un batch aléatoire\n",
    "    batches = generate_batches_cond(data, batch_size)\n",
    "    i = random.randrange(len(batches))\n",
    "    batch = batches[i]\n",
    "\n",
    "    # Génération conditionnelle\n",
    "    cond = gan.generate_cond([sample[1] for sample in batch])\n",
    "    real_sign = np.expand_dims(cond, axis=-1)\n",
    "    z = gan.generate_latent_points(latent_dim, batch_size)\n",
    "    input_model = layers.Concatenate()([z, cond])\n",
    "    generated_samples = generatorGP.predict_on_batch(input_model)\n",
    "\n",
    "    # === Traitement d'image et prédiction ===\n",
    "    for k in range(batch_size):\n",
    "        image_fake = generated_samples[k]\n",
    "        \n",
    "        # Traite une seule image et retourne le tenseur prêt à être passé au CNN\n",
    "        processed_tensor = image_processing_single(image_fake)  # ⇐ À extraire de ta fonction image_processing\n",
    "        \n",
    "        pred_sign1, pred_sign2 = modelCNN(processed_tensor.unsqueeze(0))  # Shape [1, 1, 256, 256]\n",
    "        real_sign1, real_sign2 = newTorchSign(real_sign)\n",
    "\n",
    "        err1 = criterion(real_sign1[k], pred_sign1[0]).item()\n",
    "        err2 = criterion(real_sign2[k], pred_sign2[0]).item()\n",
    "\n",
    "        all_errors_modulus1.append(err1)\n",
    "        all_errors_modulus2.append(err2)\n",
    "\n",
    "errors1 = np.array(all_errors_modulus1)\n",
    "errors2 = np.array(all_errors_modulus2)\n",
    "\n",
    "# Moyennes\n",
    "mean1 = np.mean(errors1)\n",
    "mean2 = np.mean(errors2)\n",
    "\n",
    "# Écart-types\n",
    "std1 = np.std(errors1, ddof=1)  # ddof=1 pour échantillon\n",
    "std2 = np.std(errors2, ddof=1)\n",
    "\n",
    "# Erreurs-types\n",
    "stderr1 = std1 / np.sqrt(len(errors1))\n",
    "stderr2 = std2 / np.sqrt(len(errors2))\n",
    "\n",
    "# Intervalles de confiance à 95%\n",
    "ci1 = stats.norm.interval(0.95, loc=mean1, scale=stderr1)\n",
    "ci2 = stats.norm.interval(0.95, loc=mean2, scale=stderr2)\n",
    "\n",
    "# === Affichage final ===\n",
    "print(\"\\n--- Résultats sur {:,} microstructures ---\".format(n_samples))\n",
    "print(f\"Storage modulus (MAPE) : {mean1*100:.2f} ± {stderr1*100:.2f} % (IC 95%: {ci1[0]*100:.2f} – {ci1[1]*100:.2f} %)\")\n",
    "print(f\"Loss modulus    (MAPE) : {mean2*100:.2f} ± {stderr2*100:.2f} % (IC 95%: {ci2[0]*100:.2f} – {ci2[1]*100:.2f} %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a14889f-1758-4630-801a-842a87b0a202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c0c9a-9064-42fc-8ce9-ce89e70ea219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random as rd\n",
    "from traitement_image import image_processing\n",
    "from utils import transform_batch, newTorchSign\n",
    "\n",
    "n_samples = 2\n",
    "latent_dim = 38\n",
    "\n",
    "# Générer des exemples avec le générateur\n",
    "batches = generate_batches_cond(data, n_samples)\n",
    "i = rd.randrange(len(batches))\n",
    "batch = batches[i]\n",
    "cond = gan.generate_cond([sample[1] for sample in batch])\n",
    "real_sign = np.expand_dims(cond, axis=-1)\n",
    "random_indices = np.random.choice(cond.shape[0], 2, replace=False)\n",
    "conditions_selected = cond[random_indices]\n",
    "z = gan.generate_latent_points(latent_dim, n_samples)\n",
    "input_model = layers.Concatenate()([z, conditions_selected])\n",
    "\n",
    "generated_samples = generatorGP.predict_on_batch(input_model)\n",
    "\n",
    "# Conversion des images générées (TensorFlow) en tenseur PyTorch\n",
    "fake_images_torch = transform_batch(generated_samples)\n",
    "\n",
    "# Prédiction de la signature avec le CNN-RNN\n",
    "pred_sign1, pred_sign2 = modelCNN(fake_images_torch)\n",
    "real_sign1, real_sign2 = newTorchSign(real_sign)\n",
    "\n",
    "# Affichage des images et signatures (log scale pour les courbes)\n",
    "X = np.logspace(-4, 2, real_sign1.shape[-1])  # fréquence logarithmique typique\n",
    "\n",
    "for i, generated in enumerate(generated_samples):\n",
    "    real_image = batch[i][0]\n",
    "    \n",
    "    # Affichage image\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(real_image, cmap='gray')\n",
    "    plt.title(\"Real Image\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(generated, cmap='gray')\n",
    "    plt.title(\"Generated Image\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Affichage des courbes Storage / Loss avec échelle log\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # STORAGE modulus\n",
    "    ax1.plot(X, torch.exp(real_sign1[i]).detach().numpy(), label=\"Real Sign 1\")\n",
    "    ax1.plot(X, torch.exp(pred_sign1[i]).detach().numpy(), label=\"Pred Sign 1\")\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_title(f\"Storage modulus (MAPE = {100*criterion(real_sign1[i], pred_sign1[i]):.2f}%)\")\n",
    "    ax1.set_xlabel('Frequency (rad/s)')\n",
    "    ax1.set_ylabel('Storage modulus (MPa)')\n",
    "    ax1.legend()\n",
    "\n",
    "    # LOSS modulus\n",
    "    ax2.plot(X, torch.exp(real_sign2[i]).detach().numpy(), label=\"Real Sign 2\")\n",
    "    ax2.plot(X, torch.exp(pred_sign2[i]).detach().numpy(), label=\"Pred Sign 2\")\n",
    "    ax2.set_xscale('log')\n",
    "    ax2.set_title(f\"Loss modulus (MAPE = {100*criterion(real_sign2[i], pred_sign2[i]):.2f}%)\")\n",
    "    ax2.set_xlabel('Frequency (rad/s)')\n",
    "    ax2.set_ylabel('Loss modulus (MPa)')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Traitement global\n",
    "image_processing(generated_samples, n_samples, real_sign, modelCNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a390db6d-e0f3-47f3-96ac-77e6a8ac49b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd \n",
    "from traitement_image import image_processing\n",
    "from utils import transform_batch, newTorchSign\n",
    "n_samples = 2\n",
    "latent_dim=38\n",
    "# Générer des exemples avec le générateur\n",
    "batches = generate_batches_cond(data, n_samples)\n",
    "i = rd.randrange(len(batches))\n",
    "batch = batches[i]\n",
    "cond = gan.generate_cond([sample[1] for sample in batch])\n",
    "real_sign = np.expand_dims(cond,axis=-1)\n",
    "random_indices = np.random.choice(cond.shape[0], 2, replace=False)\n",
    "conditions_selected = cond[random_indices]\n",
    "z = gan.generate_latent_points(latent_dim, n_samples)\n",
    "input_model = layers.Concatenate()([z, conditions_selected])\n",
    "\n",
    "X_fake = generatorGP.predict_on_batch(input_model)\n",
    "plt.imshow(X_fake[0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "X_fake_reshaped = (X_fake[0] * 255).astype(np.uint8).reshape(128, 128)\n",
    "image = Image.fromarray(X_fake_reshaped, mode='L') \n",
    "\n",
    "output_path = os.path.join('/Users/Bader/Desktop/Mines 2A/Projet 2A/Images génerées', 'image1.png')\n",
    "image.save(output_path)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image_path = r\"/Users/Bader/Desktop/Mines 2A/Projet 2A/Images génerées/image1.png\"\n",
    "\n",
    "with open(image_path, \"rb\") as f:\n",
    "    image_data = np.asarray(bytearray(f.read()), dtype=np.uint8)\n",
    "\n",
    "#On décode l'image\n",
    "imageenr = cv2.imdecode(image_data, cv2.IMREAD_COLOR)\n",
    "H=imageenr.shape[0]\n",
    "W=imageenr.shape[1]\n",
    "#print(imageenr)\n",
    "print(imageenr.shape)\n",
    "# #image = cv2.imread(image_gray)\n",
    "gray = cv2.cvtColor(imageenr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# #Appliquer un seuillage\n",
    "# _, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# # ON évite les petits artefacts\n",
    "# kernel = np.ones((3, 3), np.uint8)\n",
    "# thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# # On trouve les contours des clusters\n",
    "# contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # Image sur laquelle on dessine les cercles\n",
    "# output = np.zeros_like(image)\n",
    "\n",
    "# # taille fixe des cercles\n",
    "# fixed_radius = 5 \n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(output, cmap='gray')\n",
    "\n",
    "# for cnt in contours:\n",
    "#     M = cv2.moments(cnt)\n",
    "#     if M[\"m00\"] != 0:\n",
    "#         cx = int(M[\"m10\"] / M[\"m00\"] )\n",
    "#         cy = int(M[\"m01\"] / M[\"m00\"] )\n",
    "        \n",
    "#         # DOn dessine un cercle de taille fixe centré sur le cluster\n",
    "#         #cv2.circle(output, (cx, cy), fixed_radius, (255, 255, 255), -1)\n",
    "#         circle = plt.Circle((cx, cy), fixed_radius, color='white', fill=True, alpha=0.9)\n",
    "#         ax.add_patch(circle)\n",
    "\n",
    "\n",
    "# #plt.imshow(fig, cmap='gray')\n",
    "# plt.axis()\n",
    "# plt.show()\n",
    "from scipy.ndimage import gaussian_filter, distance_transform_edt\n",
    "from skimage.morphology import disk, binary_erosion\n",
    "from skimage.segmentation import watershed \n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label,regionprops\n",
    "smoothed = gaussian_filter(gray,sigma=0.5)\n",
    "\n",
    "tresh_value = threshold_otsu(smoothed)\n",
    "binary = (smoothed > tresh_value).astype(np.uint8) * 255\n",
    "\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "thresh = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "\n",
    "kernel = disk(2)\n",
    "binary_opened = binary_erosion(thresh, kernel)\n",
    "\n",
    "distance=distance_transform_edt(binary_opened)\n",
    "markers=label(distance>0.3*distance.max())\n",
    "local_maxi = watershed(-distance,markers,mask=binary_opened)\n",
    "binary_local_maxi = (local_maxi > 0).astype(np.uint8) * 255\n",
    "fig,ax= plt.subplots(1,5,figsize=(15,5))\n",
    "ax[0].imshow(imageenr,cmap='gray') ; ax[0].set_title(\"image originale\")\n",
    "ax[1].imshow(binary,cmap='gray') ; ax[1].set_title(\"image seuillée\")\n",
    "ax[2].imshow(thresh,cmap='gray') ; ax[2].set_title(\"ouverture morphologique\")\n",
    "ax[3].imshow(binary_opened,cmap='gray') ; ax[3].set_title(\"image clusters réduits\")\n",
    "ax[4].imshow(binary_local_maxi,cmap='nipy_spectral'); ax[4].set_title(\"image clusters séparés\")\n",
    "\n",
    "plt.show()\n",
    "image_bw = Image.fromarray(binary_local_maxi, mode='L')\n",
    "print(image)\n",
    "output_path = os.path.join('/Users/Bader/Desktop/Mines 2A/Projet 2A/Images génerées', 'image2.png')\n",
    "image_bw.save(output_path)\n",
    "\n",
    "image_path = r\"/Users/Bader/Desktop/Mines 2A/Projet 2A/Images génerées/image2.png\"\n",
    "\n",
    "with open(image_path, \"rb\") as f:\n",
    "    image_data = np.asarray(bytearray(f.read()), dtype=np.uint8)\n",
    "\n",
    "#On décode l'image\n",
    "imageenr = cv2.imdecode(image_data, cv2.IMREAD_COLOR)\n",
    "\n",
    "gray = cv2.cvtColor(imageenr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "#Appliquer un seuillage\n",
    "_, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# ON évite les petits artefacts\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# On trouve les contours des clusters\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Image sur laquelle on dessine les cercles\n",
    "output = np.zeros_like(imageenr)\n",
    "\n",
    "# taille fixe des cercles\n",
    "fixed_radius =imageenr.shape[0]*3.98942280401433*10**(-2)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(output, cmap='gray')\n",
    "\n",
    "\n",
    "for cnt in contours:\n",
    "    M = cv2.moments(cnt)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cx = int(M[\"m10\"] / M[\"m00\"] )\n",
    "        cy = int(M[\"m01\"] / M[\"m00\"] )\n",
    "        \n",
    "        # DOn dessine un cercle de taille fixe centré sur le cluster\n",
    "        #cv2.circle(output, (cx, cy), fixed_radius, (255, 255, 255), -1)\n",
    "        circle = plt.Circle((cx, cy), fixed_radius, color='white', fill=True, alpha=0.9)\n",
    "        ax.add_patch(circle)\n",
    "\n",
    "        translations = [\n",
    "            (-W, 0),  # Gauche\n",
    "            (W, 0),   # Droite\n",
    "            (0, -H),  # Bas\n",
    "            (0, H),   # Haut\n",
    "            (-W, -H), # Coin Bas-Gauche\n",
    "            (-W, H),  # Coin Haut-Gauche\n",
    "            (W, -H),  # Coin Bas-Droite\n",
    "            (W, H)    # Coin Haut-Droite\n",
    "        ]\n",
    "\n",
    "        for dx, dy in translations:\n",
    "            shifted_circle = plt.Circle((cx + dx, cy + dy), fixed_radius, color='white', fill=True, alpha=0.9)\n",
    "            ax.add_patch(shifted_circle)\n",
    "\n",
    "\n",
    "plt.axis()\n",
    "plt.show()\n",
    "\n",
    "dpi = 25\n",
    "figsize = ( imageenr.shape[0] / dpi, imageenr.shape[1] / dpi)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "ax.imshow(output, cmap='gray')\n",
    "\n",
    "\n",
    "for cnt in contours:\n",
    "    M = cv2.moments(cnt)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cx = int(M[\"m10\"] / M[\"m00\"] )\n",
    "        cy = int(M[\"m01\"] / M[\"m00\"] )\n",
    "        \n",
    "        # DOn dessine un cercle de taille fixe centré sur le cluster\n",
    "        #cv2.circle(output, (cx, cy), fixed_radius, (255, 255, 255), -1)\n",
    "        circle = plt.Circle((cx, cy), fixed_radius, color='white', fill=True, alpha=0.9)\n",
    "        ax.add_patch(circle)\n",
    "\n",
    "        translations = [\n",
    "            (-W, 0),  # Gauche\n",
    "            (W, 0),   # Droite\n",
    "            (0, -H),  # Bas\n",
    "            (0, H),   # Haut\n",
    "            (-W, -H), # Coin Bas-Gauche\n",
    "            (-W, H),  # Coin Haut-Gauche\n",
    "            (W, -H),  # Coin Bas-Droite\n",
    "            (W, H)    # Coin Haut-Droite\n",
    "        ]\n",
    "\n",
    "        for dx, dy in translations:\n",
    "            shifted_circle = plt.Circle((cx + dx, cy + dy), fixed_radius, color='white', fill=True, alpha=0.9)\n",
    "            ax.add_patch(shifted_circle)\n",
    "ax.set_position([0,0,1,1])\n",
    "\n",
    "ax.set_xticks([])  \n",
    "ax.set_yticks([])  \n",
    "ax.set_frame_on(False)  \n",
    "ax.set_facecolor('black')\n",
    "\n",
    "# # Calculer la taille de la figure en pouces (445 pixels / 100 DPI)\n",
    "# dpi = 100\n",
    "# figsize = ( imageenr.shape[0] / dpi, imageenr.shape[1] / dpi)\n",
    "\n",
    "# # Créer une figure de la taille de l'image\n",
    "# fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "# ax = fig.add_axes([0, 0, 1, 1])  # Axes qui remplissent toute la figure\n",
    "# ax.set_axis_off()  # Désactive les axes\n",
    "#plt.subplots_adjust(left=0, right=1, top=1, bottom=0)  # Supprime les marges\n",
    "\n",
    "\n",
    "fig.canvas.draw()\n",
    "\n",
    "\n",
    "image_array = np.array(fig.canvas.renderer.buffer_rgba())  # Récupération en RGBA\n",
    "plt.close(fig)  # Fermer la figure pour libérer la mémoire\n",
    "print(image_array.shape)\n",
    "\n",
    "# Conversion en niveaux de gris et seuillage\n",
    "gray_image = np.mean(image_array[:H, :W, :3], axis=2)  # Convertir en niveaux de gris\n",
    "binary_array = gray_image > 100  # Seuil pour obtenir une matrice de 0 et 1\n",
    "print(binary_array.shape)\n",
    "# Affichage du résultat\n",
    "plt.figure()\n",
    "plt.imshow(binary_array, cmap='gray')\n",
    "plt.title(\"Image transformée en binaire\")\n",
    "plt.show()\n",
    "# array = np.array(output)\n",
    "# plt.imshow(array, cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "# cv2.imshow(\"Clusters remplacés par cercles fixes\", output)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "# import cv2 \n",
    "# import numpy as np \n",
    "# from skimage import morphology \n",
    "# from skimage.segmentation import watershed \n",
    "# from skimage.feature import peak_local_max \n",
    "# from scipy import ndimage \n",
    "# from skimage.transform import resize\n",
    "\n",
    "# # # Charger l'image en niveaux de gris \n",
    "# # image = cv2.imread('image.png', cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    "# # Appliquer un seuillage binaire\n",
    "# _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "# # Suppression du bruit avec une ouverture morphologique\n",
    "# kernel = np.ones((3,3), np.uint8)\n",
    "# opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "# # Déterminer l’arrière-plan (zone sûre)\n",
    "# sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "\n",
    "# # Déterminer l’avant-plan (objets à segmenter)\n",
    "# dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "# _, sure_fg = cv2.threshold(dist_transform, 0.5 * dist_transform.max(), 255, 0)\n",
    "\n",
    "# # Trouver les marqueurs\n",
    "# sure_fg = np.uint8(sure_fg)\n",
    "# unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "# _, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "# # Ajouter 1 à tous les marqueurs pour éviter l'étiquette 0\n",
    "# markers = markers + 1\n",
    "\n",
    "# # Les pixels inconnus sont marqués en 0\n",
    "# markers[unknown == 255] = 0\n",
    "\n",
    "# # Appliquer Watershed\n",
    "# cv2.watershed(imageenr, markers)\n",
    "\n",
    "# # Colorer les contours en rouge\n",
    "# imageenr[markers == -1] = [0, 0, 255]\n",
    "\n",
    "# # Afficher l’image segmentée\n",
    "# plt.figure(figsize=(8,8))\n",
    "# plt.imshow(cv2.cvtColor(imageenr, cv2.COLOR_BGR2RGB))\n",
    "# plt.title(\"Segmentation Watershed\")\n",
    "# plt.show()\n",
    "\n",
    "# # Étape 1: Filtrage Gaussien et Seuillage d'Otsu \n",
    "# blurred = cv2.GaussianBlur(gray, (5, 5), 0.5) \n",
    "# _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU) \n",
    "\n",
    "# # Étape 2: Opération Morphologique d'Ouverture \n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (4, 4)) \n",
    "# opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel) \n",
    "\n",
    "# # Étape 3: Transformation de Distance Euclidienne et Ligne de Partage des Eaux \n",
    "# distance = ndimage.distance_transform_edt(opened) \n",
    "# # print(distance.shape)\n",
    "# # local_maxi = peak_local_max(distance, footprint=np.ones((4, 4)), labels=opened) \n",
    "# # print(local_maxi.shape)\n",
    "# # markers = ndimage.label(local_maxi)[0] \n",
    "# # print(markers.shape)\n",
    "# # print(opened.shape)\n",
    "# # if markers.shape != opened.shape:\n",
    "# #     # Resize markers to match the shape of opened\n",
    "# #     markers = resize(markers, opened.shape, order=0, mode='constant', cval=0, clip=True)\n",
    "# markers = ndimage.label(opened)[0]\n",
    "# labels = watershed(-distance, markers, mask=opened) \n",
    "\n",
    "# # Afficher les résultats \n",
    "# #cv2.imshow('Original', imageenr)\n",
    "# cv2.imshow('Binary', binary)\n",
    "# cv2.imshow('Opened', opened)\n",
    "# cv2.imshow('Watershed', labels.astype(np.uint8) * 255)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# gray = cv2.cvtColor(binary, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# #Appliquer un seuillage\n",
    "# _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# # Appliquer une ouverture morphologique pour éviter les petits artefacts\n",
    "# kernel = np.ones((5, 5), np.uint8)\n",
    "# thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# # Trouver les contours des clusters\n",
    "# contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # Créer une image noire pour dessiner les cercles\n",
    "# output = np.zeros_like(image)\n",
    "\n",
    "# # Définir la taille fixe des cercles\n",
    "# fixed_radius = 5  # Ajuste selon ton besoin\n",
    "\n",
    "# # Parcourir chaque cluster détecté\n",
    "# for cnt in contours:\n",
    "#     # Trouver le centre de gravité du cluster\n",
    "#     M = cv2.moments(cnt)\n",
    "#     if M[\"m00\"] != 0:\n",
    "#         cx = int(M[\"m10\"] / M[\"m00\"] )\n",
    "#         cy = int(M[\"m01\"] / M[\"m00\"] )\n",
    "#         # Dessiner un cercle de taille fixe centré sur le cluster\n",
    "#         cv2.circle(output, (cx, cy), fixed_radius, (255, 255, 255), -1)\n",
    "\n",
    "# # Afficher le résultat\n",
    "# cv2.imshow(\"Clusters remplacés par cercles fixes\", output)\n",
    "# # cv2.waitKey(0)\n",
    "# # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d57b6-bc06-4788-8966-1c7fdeed3707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
